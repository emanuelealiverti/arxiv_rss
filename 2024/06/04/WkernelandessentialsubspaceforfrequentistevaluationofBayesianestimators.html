<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>W-kernel and essential subspace for frequentist evaluation of Bayesian estimators</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="W-kernel and essential subspace for frequentist evaluation of Bayesian estimators" />
<meta name="author" content="Yukito Iba" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The posterior covariance matrix W defined by the log-likelihood of each observation plays important roles both in the sensitivity analysis and frequentist evaluation of the Bayesian estimators. This study is focused on the matrix W and its principal space; we term the latter as an essential subspace. Projections to the essential subspace realize dimensional reduction in the sensitivity analysis and frequentist evaluation. A key tool for treating frequentist properties is the recently proposed Bayesian infinitesimal jackknife approximation(Giordano and Broderick (2023)). The matrix W can be interpreted as a reproducing kernel and is denoted as W-kernel. Using W-kernel, the essential subspace is expressed as a principal space given by the kernel principal component analysis. A relation to the Fisher kernel and neural tangent kernel is established, which elucidates the connection to the classical asymptotic theory. We also discuss a type of Bayesian-frequentist duality, naturally appeared from the kernel framework. Two applications are discussed: the selection of a representative set of observations and dimensional reduction in the approximate bootstrap. In the former, incomplete Cholesky decomposition is introduced as an efficient method for computing the essential subspace. In the latter, different implementations of the approximate bootstrap for posterior means are compared." />
<meta property="og:description" content="The posterior covariance matrix W defined by the log-likelihood of each observation plays important roles both in the sensitivity analysis and frequentist evaluation of the Bayesian estimators. This study is focused on the matrix W and its principal space; we term the latter as an essential subspace. Projections to the essential subspace realize dimensional reduction in the sensitivity analysis and frequentist evaluation. A key tool for treating frequentist properties is the recently proposed Bayesian infinitesimal jackknife approximation(Giordano and Broderick (2023)). The matrix W can be interpreted as a reproducing kernel and is denoted as W-kernel. Using W-kernel, the essential subspace is expressed as a principal space given by the kernel principal component analysis. A relation to the Fisher kernel and neural tangent kernel is established, which elucidates the connection to the classical asymptotic theory. We also discuss a type of Bayesian-frequentist duality, naturally appeared from the kernel framework. Two applications are discussed: the selection of a representative set of observations and dimensional reduction in the approximate bootstrap. In the former, incomplete Cholesky decomposition is introduced as an efficient method for computing the essential subspace. In the latter, different implementations of the approximate bootstrap for posterior means are compared." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/06/04/WkernelandessentialsubspaceforfrequentistevaluationofBayesianestimators.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/06/04/WkernelandessentialsubspaceforfrequentistevaluationofBayesianestimators.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-04T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="W-kernel and essential subspace for frequentist evaluation of Bayesian estimators" />
<script type="application/ld+json">
{"description":"The posterior covariance matrix W defined by the log-likelihood of each observation plays important roles both in the sensitivity analysis and frequentist evaluation of the Bayesian estimators. This study is focused on the matrix W and its principal space; we term the latter as an essential subspace. Projections to the essential subspace realize dimensional reduction in the sensitivity analysis and frequentist evaluation. A key tool for treating frequentist properties is the recently proposed Bayesian infinitesimal jackknife approximation(Giordano and Broderick (2023)). The matrix W can be interpreted as a reproducing kernel and is denoted as W-kernel. Using W-kernel, the essential subspace is expressed as a principal space given by the kernel principal component analysis. A relation to the Fisher kernel and neural tangent kernel is established, which elucidates the connection to the classical asymptotic theory. We also discuss a type of Bayesian-frequentist duality, naturally appeared from the kernel framework. Two applications are discussed: the selection of a representative set of observations and dimensional reduction in the approximate bootstrap. In the former, incomplete Cholesky decomposition is introduced as an efficient method for computing the essential subspace. In the latter, different implementations of the approximate bootstrap for posterior means are compared.","author":{"@type":"Person","name":"Yukito Iba"},"datePublished":"2024-06-04T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/04/WkernelandessentialsubspaceforfrequentistevaluationofBayesianestimators.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/04/WkernelandessentialsubspaceforfrequentistevaluationofBayesianestimators.html","headline":"W-kernel and essential subspace for frequentist evaluation of Bayesian estimators","@type":"BlogPosting","dateModified":"2024-06-04T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-06-04 00:00:00 +0000">06-04</time>
  </p>
  
  <h1>W-kernel and essential subspace for frequentist evaluation of Bayesian estimators</h1>
  <br>Yukito Iba</h3>
  <br> [stat.ME,cond-mat.stat-mech,stat.ML]

  <p>The posterior covariance matrix W defined by the log-likelihood of each observation plays important roles both in the sensitivity analysis and frequentist evaluation of the Bayesian estimators. This study is focused on the matrix W and its principal space; we term the latter as an essential subspace. Projections to the essential subspace realize dimensional reduction in the sensitivity analysis and frequentist evaluation. A key tool for treating frequentist properties is the recently proposed Bayesian infinitesimal jackknife approximation(Giordano and Broderick (2023)). The matrix W can be interpreted as a reproducing kernel and is denoted as W-kernel. Using W-kernel, the essential subspace is expressed as a principal space given by the kernel principal component analysis. A relation to the Fisher kernel and neural tangent kernel is established, which elucidates the connection to the classical asymptotic theory. We also discuss a type of Bayesian-frequentist duality, naturally appeared from the kernel framework. Two applications are discussed: the selection of a representative set of observations and dimensional reduction in the approximate bootstrap. In the former, incomplete Cholesky decomposition is introduced as an efficient method for computing the essential subspace. In the latter, different implementations of the approximate bootstrap for posterior means are compared.</p>

<p><a href="https://arxiv.org/abs/2311.13017">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>