<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Benchmarking M6 Competitors: An Analysis of Financial Metrics and Discussion of Incentives</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Benchmarking M6 Competitors: An Analysis of Financial Metrics and Discussion of Incentives" />
<meta name="author" content="Matthew J. Schneider, Rufus Rankin, Prabir Burman, Alexander Aue" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The M6 Competition assessed the performance of competitors using a ranked probability score and an information ratio (IR). While these metrics do well at picking the winners in the competition, crucial questions remain for investors with longer-term incentives. To address these questions, we compare the competitors’ performance to a number of conventional (long-only) and alternative indices using standard industry metrics. We apply factor models to the competitors’ returns and show the difficulty for any competitor to demonstrate a statistically significant value-add above industry-standard benchmarks within the short timeframe of the competition. We also uncover that most competitors generated lower risk-adjusted returns and lower maximum drawdowns than randomly selected portfolios, and that most competitors could not generate significant out-performance in raw returns. We further introduce two new strategies by picking the competitors with the best (Superstars) and worst (Superlosers) recent performance and show that it is challenging to identify skill amongst investment managers. Overall, our findings highlight the difference in incentives for competitors over professional investors, where the upside of winning the competition dwarfs the potential downside of not winning to maximize fees over an extended period of time." />
<meta property="og:description" content="The M6 Competition assessed the performance of competitors using a ranked probability score and an information ratio (IR). While these metrics do well at picking the winners in the competition, crucial questions remain for investors with longer-term incentives. To address these questions, we compare the competitors’ performance to a number of conventional (long-only) and alternative indices using standard industry metrics. We apply factor models to the competitors’ returns and show the difficulty for any competitor to demonstrate a statistically significant value-add above industry-standard benchmarks within the short timeframe of the competition. We also uncover that most competitors generated lower risk-adjusted returns and lower maximum drawdowns than randomly selected portfolios, and that most competitors could not generate significant out-performance in raw returns. We further introduce two new strategies by picking the competitors with the best (Superstars) and worst (Superlosers) recent performance and show that it is challenging to identify skill amongst investment managers. Overall, our findings highlight the difference in incentives for competitors over professional investors, where the upside of winning the competition dwarfs the potential downside of not winning to maximize fees over an extended period of time." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/06/28/BenchmarkingM6CompetitorsAnAnalysisofFinancialMetricsandDiscussionofIncentives.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/06/28/BenchmarkingM6CompetitorsAnAnalysisofFinancialMetricsandDiscussionofIncentives.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-28T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Benchmarking M6 Competitors: An Analysis of Financial Metrics and Discussion of Incentives" />
<script type="application/ld+json">
{"description":"The M6 Competition assessed the performance of competitors using a ranked probability score and an information ratio (IR). While these metrics do well at picking the winners in the competition, crucial questions remain for investors with longer-term incentives. To address these questions, we compare the competitors’ performance to a number of conventional (long-only) and alternative indices using standard industry metrics. We apply factor models to the competitors’ returns and show the difficulty for any competitor to demonstrate a statistically significant value-add above industry-standard benchmarks within the short timeframe of the competition. We also uncover that most competitors generated lower risk-adjusted returns and lower maximum drawdowns than randomly selected portfolios, and that most competitors could not generate significant out-performance in raw returns. We further introduce two new strategies by picking the competitors with the best (Superstars) and worst (Superlosers) recent performance and show that it is challenging to identify skill amongst investment managers. Overall, our findings highlight the difference in incentives for competitors over professional investors, where the upside of winning the competition dwarfs the potential downside of not winning to maximize fees over an extended period of time.","author":{"@type":"Person","name":"Matthew J. Schneider, Rufus Rankin, Prabir Burman, Alexander Aue"},"headline":"Benchmarking M6 Competitors: An Analysis of Financial Metrics and Discussion of Incentives","dateModified":"2024-06-28T00:00:00+00:00","datePublished":"2024-06-28T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/28/BenchmarkingM6CompetitorsAnAnalysisofFinancialMetricsandDiscussionofIncentives.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/28/BenchmarkingM6CompetitorsAnAnalysisofFinancialMetricsandDiscussionofIncentives.html","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-06-28 00:00:00 +0000">06-28</time>
  </p>
  
  <h1>Benchmarking M6 Competitors: An Analysis of Financial Metrics and Discussion of Incentives</h1>
  <br>Matthew J. Schneider, Rufus Rankin, Prabir Burman, Alexander Aue</h3>
  <br> [stat.AP]

  <p>The M6 Competition assessed the performance of competitors using a ranked probability score and an information ratio (IR). While these metrics do well at picking the winners in the competition, crucial questions remain for investors with longer-term incentives. To address these questions, we compare the competitors’ performance to a number of conventional (long-only) and alternative indices using standard industry metrics. We apply factor models to the competitors’ returns and show the difficulty for any competitor to demonstrate a statistically significant value-add above industry-standard benchmarks within the short timeframe of the competition. We also uncover that most competitors generated lower risk-adjusted returns and lower maximum drawdowns than randomly selected portfolios, and that most competitors could not generate significant out-performance in raw returns. We further introduce two new strategies by picking the competitors with the best (Superstars) and worst (Superlosers) recent performance and show that it is challenging to identify skill amongst investment managers. Overall, our findings highlight the difference in incentives for competitors over professional investors, where the upside of winning the competition dwarfs the potential downside of not winning to maximize fees over an extended period of time.</p>

<p><a href="https://arxiv.org/abs/2406.19105">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>