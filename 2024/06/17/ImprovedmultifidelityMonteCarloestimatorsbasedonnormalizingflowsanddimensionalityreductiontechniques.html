<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Improved multifidelity Monte Carlo estimators based on normalizing flows and dimensionality reduction techniques</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Improved multifidelity Monte Carlo estimators based on normalizing flows and dimensionality reduction techniques" />
<meta name="author" content="Andrea Zanoni, Gianluca Geraci, Matteo Salvador, Karthik Menon, Alison L. Marsden, Daniele E. Schiavazzi" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We study the problem of multifidelity uncertainty propagation for computationally expensive models. In particular, we consider the general setting where the high-fidelity and low-fidelity models have a dissimilar parameterization both in terms of number of random inputs and their probability distributions, which can be either known in closed form or provided through samples. We derive novel multifidelity Monte Carlo estimators which rely on a shared subspace between the high-fidelity and low-fidelity models where the parameters follow the same probability distribution, i.e., a standard Gaussian. We build the shared space employing normalizing flows to map different probability distributions into a common one, together with linear and nonlinear dimensionality reduction techniques, active subspaces and autoencoders, respectively, which capture the subspaces where the models vary the most. We then compose the existing low-fidelity model with these transformations and construct modified models with an increased correlation with the high-fidelity model, which therefore yield multifidelity Monte Carlo estimators with reduced variance. A series of numerical experiments illustrate the properties and advantages of our approaches." />
<meta property="og:description" content="We study the problem of multifidelity uncertainty propagation for computationally expensive models. In particular, we consider the general setting where the high-fidelity and low-fidelity models have a dissimilar parameterization both in terms of number of random inputs and their probability distributions, which can be either known in closed form or provided through samples. We derive novel multifidelity Monte Carlo estimators which rely on a shared subspace between the high-fidelity and low-fidelity models where the parameters follow the same probability distribution, i.e., a standard Gaussian. We build the shared space employing normalizing flows to map different probability distributions into a common one, together with linear and nonlinear dimensionality reduction techniques, active subspaces and autoencoders, respectively, which capture the subspaces where the models vary the most. We then compose the existing low-fidelity model with these transformations and construct modified models with an increased correlation with the high-fidelity model, which therefore yield multifidelity Monte Carlo estimators with reduced variance. A series of numerical experiments illustrate the properties and advantages of our approaches." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/06/17/ImprovedmultifidelityMonteCarloestimatorsbasedonnormalizingflowsanddimensionalityreductiontechniques.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/06/17/ImprovedmultifidelityMonteCarloestimatorsbasedonnormalizingflowsanddimensionalityreductiontechniques.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-17T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Improved multifidelity Monte Carlo estimators based on normalizing flows and dimensionality reduction techniques" />
<script type="application/ld+json">
{"description":"We study the problem of multifidelity uncertainty propagation for computationally expensive models. In particular, we consider the general setting where the high-fidelity and low-fidelity models have a dissimilar parameterization both in terms of number of random inputs and their probability distributions, which can be either known in closed form or provided through samples. We derive novel multifidelity Monte Carlo estimators which rely on a shared subspace between the high-fidelity and low-fidelity models where the parameters follow the same probability distribution, i.e., a standard Gaussian. We build the shared space employing normalizing flows to map different probability distributions into a common one, together with linear and nonlinear dimensionality reduction techniques, active subspaces and autoencoders, respectively, which capture the subspaces where the models vary the most. We then compose the existing low-fidelity model with these transformations and construct modified models with an increased correlation with the high-fidelity model, which therefore yield multifidelity Monte Carlo estimators with reduced variance. A series of numerical experiments illustrate the properties and advantages of our approaches.","datePublished":"2024-06-17T00:00:00+00:00","dateModified":"2024-06-17T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/17/ImprovedmultifidelityMonteCarloestimatorsbasedonnormalizingflowsanddimensionalityreductiontechniques.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/17/ImprovedmultifidelityMonteCarloestimatorsbasedonnormalizingflowsanddimensionalityreductiontechniques.html","author":{"@type":"Person","name":"Andrea Zanoni, Gianluca Geraci, Matteo Salvador, Karthik Menon, Alison L. Marsden, Daniele E. Schiavazzi"},"@type":"BlogPosting","headline":"Improved multifidelity Monte Carlo estimators based on normalizing flows and dimensionality reduction techniques","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-06-17 00:00:00 +0000">06-17</time>
  </p>
  
  <h1>Improved multifidelity Monte Carlo estimators based on normalizing flows and dimensionality reduction techniques</h1>
  <br>Andrea Zanoni, Gianluca Geraci, Matteo Salvador, Karthik Menon, Alison L. Marsden, Daniele E. Schiavazzi</h3>
  <br> [stat.ME]

  <p>We study the problem of multifidelity uncertainty propagation for computationally expensive models. In particular, we consider the general setting where the high-fidelity and low-fidelity models have a dissimilar parameterization both in terms of number of random inputs and their probability distributions, which can be either known in closed form or provided through samples. We derive novel multifidelity Monte Carlo estimators which rely on a shared subspace between the high-fidelity and low-fidelity models where the parameters follow the same probability distribution, i.e., a standard Gaussian. We build the shared space employing normalizing flows to map different probability distributions into a common one, together with linear and nonlinear dimensionality reduction techniques, active subspaces and autoencoders, respectively, which capture the subspaces where the models vary the most. We then compose the existing low-fidelity model with these transformations and construct modified models with an increased correlation with the high-fidelity model, which therefore yield multifidelity Monte Carlo estimators with reduced variance. A series of numerical experiments illustrate the properties and advantages of our approaches.</p>

<p><a href="https://arxiv.org/abs/2312.12361">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>