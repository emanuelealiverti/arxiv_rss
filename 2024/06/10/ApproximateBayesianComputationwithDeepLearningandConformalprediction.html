<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Approximate Bayesian Computation with Deep Learning and Conformal prediction</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Approximate Bayesian Computation with Deep Learning and Conformal prediction" />
<meta name="author" content="Meili Baragatti, Bertrand Cloez, David Métivier, Isabelle Sanchez" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Approximate Bayesian Computation (ABC) methods are commonly used to approximate posterior distributions in models with unknown or computationally intractable likelihoods. Classical ABC methods are based on nearest neighbor type algorithms and rely on the choice of so-called summary statistics, distances between datasets and a tolerance threshold. Recently, methods combining ABC with more complex machine learning algorithms have been proposed to mitigate the impact of these “user-choices”. In this paper, we propose the first, to our knowledge, ABC method completely free of summary statistics, distance and tolerance threshold. Moreover, in contrast with usual generalizations of the ABC method, it associates a confidence interval (having a proper frequentist marginal coverage) with the posterior mean estimation (or other moment-type estimates). Our method, ABCD-Conformal, uses a neural network with Monte Carlo Dropout to provide an estimation of the posterior mean (or others moment type functional), and conformal theory to obtain associated confidence sets. Efficient for estimating multidimensional parameters, we test this new method on three different applications and compare it with other ABC methods in the literature." />
<meta property="og:description" content="Approximate Bayesian Computation (ABC) methods are commonly used to approximate posterior distributions in models with unknown or computationally intractable likelihoods. Classical ABC methods are based on nearest neighbor type algorithms and rely on the choice of so-called summary statistics, distances between datasets and a tolerance threshold. Recently, methods combining ABC with more complex machine learning algorithms have been proposed to mitigate the impact of these “user-choices”. In this paper, we propose the first, to our knowledge, ABC method completely free of summary statistics, distance and tolerance threshold. Moreover, in contrast with usual generalizations of the ABC method, it associates a confidence interval (having a proper frequentist marginal coverage) with the posterior mean estimation (or other moment-type estimates). Our method, ABCD-Conformal, uses a neural network with Monte Carlo Dropout to provide an estimation of the posterior mean (or others moment type functional), and conformal theory to obtain associated confidence sets. Efficient for estimating multidimensional parameters, we test this new method on three different applications and compare it with other ABC methods in the literature." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/06/10/ApproximateBayesianComputationwithDeepLearningandConformalprediction.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/06/10/ApproximateBayesianComputationwithDeepLearningandConformalprediction.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-10T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Approximate Bayesian Computation with Deep Learning and Conformal prediction" />
<script type="application/ld+json">
{"description":"Approximate Bayesian Computation (ABC) methods are commonly used to approximate posterior distributions in models with unknown or computationally intractable likelihoods. Classical ABC methods are based on nearest neighbor type algorithms and rely on the choice of so-called summary statistics, distances between datasets and a tolerance threshold. Recently, methods combining ABC with more complex machine learning algorithms have been proposed to mitigate the impact of these “user-choices”. In this paper, we propose the first, to our knowledge, ABC method completely free of summary statistics, distance and tolerance threshold. Moreover, in contrast with usual generalizations of the ABC method, it associates a confidence interval (having a proper frequentist marginal coverage) with the posterior mean estimation (or other moment-type estimates). Our method, ABCD-Conformal, uses a neural network with Monte Carlo Dropout to provide an estimation of the posterior mean (or others moment type functional), and conformal theory to obtain associated confidence sets. Efficient for estimating multidimensional parameters, we test this new method on three different applications and compare it with other ABC methods in the literature.","datePublished":"2024-06-10T00:00:00+00:00","dateModified":"2024-06-10T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/10/ApproximateBayesianComputationwithDeepLearningandConformalprediction.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/10/ApproximateBayesianComputationwithDeepLearningandConformalprediction.html","author":{"@type":"Person","name":"Meili Baragatti, Bertrand Cloez, David Métivier, Isabelle Sanchez"},"@type":"BlogPosting","headline":"Approximate Bayesian Computation with Deep Learning and Conformal prediction","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-06-10 00:00:00 +0000">06-10</time>
  </p>
  
  <h1>Approximate Bayesian Computation with Deep Learning and Conformal prediction</h1>
  <br>Meili Baragatti, Bertrand Cloez, David Métivier, Isabelle Sanchez</h3>
  <br> [stat.ME]

  <p>Approximate Bayesian Computation (ABC) methods are commonly used to approximate posterior distributions in models with unknown or computationally intractable likelihoods. Classical ABC methods are based on nearest neighbor type algorithms and rely on the choice of so-called summary statistics, distances between datasets and a tolerance threshold. Recently, methods combining ABC with more complex machine learning algorithms have been proposed to mitigate the impact of these “user-choices”. In this paper, we propose the first, to our knowledge, ABC method completely free of summary statistics, distance and tolerance threshold. Moreover, in contrast with usual generalizations of the ABC method, it associates a confidence interval (having a proper frequentist marginal coverage) with the posterior mean estimation (or other moment-type estimates).
  Our method, ABCD-Conformal, uses a neural network with Monte Carlo Dropout to provide an estimation of the posterior mean (or others moment type functional), and conformal theory to obtain associated confidence sets. Efficient for estimating multidimensional parameters, we test this new method on three different applications and compare it with other ABC methods in the literature.</p>

<p><a href="https://arxiv.org/abs/2406.04874">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>