<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Computationally efficient multi-level Gaussian process regression for functional data observed under completely or partially regular sampling designs</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Computationally efficient multi-level Gaussian process regression for functional data observed under completely or partially regular sampling designs" />
<meta name="author" content="Adam Gorm Hoffmann, Claus Thorn Ekstr{\o}m, Andreas Kryger Jensen" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Gaussian process regression is a frequently used statistical method for flexible yet fully probabilistic non-linear regression modeling. A common obstacle is its computational complexity which scales poorly with the number of observations. This is especially an issue when applying Gaussian process models to multiple functions simultaneously in various applications of functional data analysis. We consider a multi-level Gaussian process regression model where a common mean function and individual subject-specific deviations are modeled simultaneously as latent Gaussian processes. We derive exact analytic and computationally efficient expressions for the log-likelihood function and the posterior distributions in the case where the observations are sampled on either a completely or partially regular grid. This enables us to fit the model to large data sets that are currently computationally inaccessible using a standard implementation. We show through a simulation study that our analytic expressions are several orders of magnitude faster compared to a standard implementation, and we provide an implementation in the probabilistic programming language Stan." />
<meta property="og:description" content="Gaussian process regression is a frequently used statistical method for flexible yet fully probabilistic non-linear regression modeling. A common obstacle is its computational complexity which scales poorly with the number of observations. This is especially an issue when applying Gaussian process models to multiple functions simultaneously in various applications of functional data analysis. We consider a multi-level Gaussian process regression model where a common mean function and individual subject-specific deviations are modeled simultaneously as latent Gaussian processes. We derive exact analytic and computationally efficient expressions for the log-likelihood function and the posterior distributions in the case where the observations are sampled on either a completely or partially regular grid. This enables us to fit the model to large data sets that are currently computationally inaccessible using a standard implementation. We show through a simulation study that our analytic expressions are several orders of magnitude faster compared to a standard implementation, and we provide an implementation in the probabilistic programming language Stan." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/06/21/ComputationallyefficientmultilevelGaussianprocessregressionforfunctionaldataobservedundercompletelyorpartiallyregularsamplingdesigns.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/06/21/ComputationallyefficientmultilevelGaussianprocessregressionforfunctionaldataobservedundercompletelyorpartiallyregularsamplingdesigns.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-21T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Computationally efficient multi-level Gaussian process regression for functional data observed under completely or partially regular sampling designs" />
<script type="application/ld+json">
{"description":"Gaussian process regression is a frequently used statistical method for flexible yet fully probabilistic non-linear regression modeling. A common obstacle is its computational complexity which scales poorly with the number of observations. This is especially an issue when applying Gaussian process models to multiple functions simultaneously in various applications of functional data analysis. We consider a multi-level Gaussian process regression model where a common mean function and individual subject-specific deviations are modeled simultaneously as latent Gaussian processes. We derive exact analytic and computationally efficient expressions for the log-likelihood function and the posterior distributions in the case where the observations are sampled on either a completely or partially regular grid. This enables us to fit the model to large data sets that are currently computationally inaccessible using a standard implementation. We show through a simulation study that our analytic expressions are several orders of magnitude faster compared to a standard implementation, and we provide an implementation in the probabilistic programming language Stan.","datePublished":"2024-06-21T00:00:00+00:00","dateModified":"2024-06-21T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/21/ComputationallyefficientmultilevelGaussianprocessregressionforfunctionaldataobservedundercompletelyorpartiallyregularsamplingdesigns.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/21/ComputationallyefficientmultilevelGaussianprocessregressionforfunctionaldataobservedundercompletelyorpartiallyregularsamplingdesigns.html","author":{"@type":"Person","name":"Adam Gorm Hoffmann, Claus Thorn Ekstr{\\o}m, Andreas Kryger Jensen"},"@type":"BlogPosting","headline":"Computationally efficient multi-level Gaussian process regression for functional data observed under completely or partially regular sampling designs","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-06-21 00:00:00 +0000">06-21</time>
  </p>
  
  <h1>Computationally efficient multi-level Gaussian process regression for functional data observed under completely or partially regular sampling designs</h1>
  <br>Adam Gorm Hoffmann, Claus Thorn Ekstr{\o}m, Andreas Kryger Jensen</h3>
  <br> [stat.ME,stat.CO]

  <p>Gaussian process regression is a frequently used statistical method for flexible yet fully probabilistic non-linear regression modeling. A common obstacle is its computational complexity which scales poorly with the number of observations. This is especially an issue when applying Gaussian process models to multiple functions simultaneously in various applications of functional data analysis.
  We consider a multi-level Gaussian process regression model where a common mean function and individual subject-specific deviations are modeled simultaneously as latent Gaussian processes. We derive exact analytic and computationally efficient expressions for the log-likelihood function and the posterior distributions in the case where the observations are sampled on either a completely or partially regular grid. This enables us to fit the model to large data sets that are currently computationally inaccessible using a standard implementation. We show through a simulation study that our analytic expressions are several orders of magnitude faster compared to a standard implementation, and we provide an implementation in the probabilistic programming language Stan.</p>

<p><a href="https://arxiv.org/abs/2406.13691">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>