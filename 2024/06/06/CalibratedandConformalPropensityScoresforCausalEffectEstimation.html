<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Calibrated and Conformal Propensity Scores for Causal Effect Estimation</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Calibrated and Conformal Propensity Scores for Causal Effect Estimation" />
<meta name="author" content="Shachi Deshpande, Volodymyr Kuleshov" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Propensity scores are commonly used to estimate treatment effects from observational data. We argue that the probabilistic output of a learned propensity score model should be calibrated – i.e., a predictive treatment probability of 90% should correspond to 90% of individuals being assigned the treatment group – and we propose simple recalibration techniques to ensure this property. We prove that calibration is a necessary condition for unbiased treatment effect estimation when using popular inverse propensity weighted and doubly robust estimators. We derive error bounds on causal effect estimates that directly relate to the quality of uncertainties provided by the probabilistic propensity score model and show that calibration strictly improves this error bound while also avoiding extreme propensity weights. We demonstrate improved causal effect estimation with calibrated propensity scores in several tasks including high-dimensional image covariates and genome-wide association studies (GWASs). Calibrated propensity scores improve the speed of GWAS analysis by more than two-fold by enabling the use of simpler models that are faster to train." />
<meta property="og:description" content="Propensity scores are commonly used to estimate treatment effects from observational data. We argue that the probabilistic output of a learned propensity score model should be calibrated – i.e., a predictive treatment probability of 90% should correspond to 90% of individuals being assigned the treatment group – and we propose simple recalibration techniques to ensure this property. We prove that calibration is a necessary condition for unbiased treatment effect estimation when using popular inverse propensity weighted and doubly robust estimators. We derive error bounds on causal effect estimates that directly relate to the quality of uncertainties provided by the probabilistic propensity score model and show that calibration strictly improves this error bound while also avoiding extreme propensity weights. We demonstrate improved causal effect estimation with calibrated propensity scores in several tasks including high-dimensional image covariates and genome-wide association studies (GWASs). Calibrated propensity scores improve the speed of GWAS analysis by more than two-fold by enabling the use of simpler models that are faster to train." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/06/06/CalibratedandConformalPropensityScoresforCausalEffectEstimation.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/06/06/CalibratedandConformalPropensityScoresforCausalEffectEstimation.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-06T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Calibrated and Conformal Propensity Scores for Causal Effect Estimation" />
<script type="application/ld+json">
{"description":"Propensity scores are commonly used to estimate treatment effects from observational data. We argue that the probabilistic output of a learned propensity score model should be calibrated – i.e., a predictive treatment probability of 90% should correspond to 90% of individuals being assigned the treatment group – and we propose simple recalibration techniques to ensure this property. We prove that calibration is a necessary condition for unbiased treatment effect estimation when using popular inverse propensity weighted and doubly robust estimators. We derive error bounds on causal effect estimates that directly relate to the quality of uncertainties provided by the probabilistic propensity score model and show that calibration strictly improves this error bound while also avoiding extreme propensity weights. We demonstrate improved causal effect estimation with calibrated propensity scores in several tasks including high-dimensional image covariates and genome-wide association studies (GWASs). Calibrated propensity scores improve the speed of GWAS analysis by more than two-fold by enabling the use of simpler models that are faster to train.","author":{"@type":"Person","name":"Shachi Deshpande, Volodymyr Kuleshov"},"datePublished":"2024-06-06T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/06/CalibratedandConformalPropensityScoresforCausalEffectEstimation.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/06/06/CalibratedandConformalPropensityScoresforCausalEffectEstimation.html","headline":"Calibrated and Conformal Propensity Scores for Causal Effect Estimation","@type":"BlogPosting","dateModified":"2024-06-06T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-06-06 00:00:00 +0000">06-06</time>
  </p>
  
  <h1>Calibrated and Conformal Propensity Scores for Causal Effect Estimation</h1>
  <br>Shachi Deshpande, Volodymyr Kuleshov</h3>
  <br> [stat.ME]

  <p>Propensity scores are commonly used to estimate treatment effects from observational data. We argue that the probabilistic output of a learned propensity score model should be calibrated – i.e., a predictive treatment probability of 90% should correspond to 90% of individuals being assigned the treatment group – and we propose simple recalibration techniques to ensure this property. We prove that calibration is a necessary condition for unbiased treatment effect estimation when using popular inverse propensity weighted and doubly robust estimators. We derive error bounds on causal effect estimates that directly relate to the quality of uncertainties provided by the probabilistic propensity score model and show that calibration strictly improves this error bound while also avoiding extreme propensity weights. We demonstrate improved causal effect estimation with calibrated propensity scores in several tasks including high-dimensional image covariates and genome-wide association studies (GWASs). Calibrated propensity scores improve the speed of GWAS analysis by more than two-fold by enabling the use of simpler models that are faster to train.</p>

<p><a href="https://arxiv.org/abs/2306.00382">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>