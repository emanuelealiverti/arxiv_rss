<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Robust Bayesian Inference for Berkson and Classical Measurement Error Models</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Robust Bayesian Inference for Berkson and Classical Measurement Error Models" />
<meta name="author" content="Charita Dellaporta, Theodoros Damoulas" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Measurement error occurs when a covariate influencing a response variable is corrupted by noise. This can lead to misleading inference outcomes, particularly in problems where accurately estimating the relationship between covariates and response variables is crucial, such as causal effect estimation. Existing methods for dealing with measurement error often rely on strong assumptions such as knowledge of the error distribution or its variance and availability of replicated measurements of the covariates. We propose a Bayesian Nonparametric Learning framework that is robust to mismeasured covariates, does not require the preceding assumptions, and can incorporate prior beliefs about the error distribution. This approach gives rise to a general framework that is suitable for both Classical and Berkson error models via the appropriate specification of the prior centering measure of a Dirichlet Process (DP). Moreover, it offers flexibility in the choice of loss function depending on the type of regression model. We provide bounds on the generalization error based on the Maximum Mean Discrepancy (MMD) loss which allows for generalization to non-Gaussian distributed errors and nonlinear covariate-response relationships. We showcase the effectiveness of the proposed framework versus prior art in real-world problems containing either Berkson or Classical measurement errors." />
<meta property="og:description" content="Measurement error occurs when a covariate influencing a response variable is corrupted by noise. This can lead to misleading inference outcomes, particularly in problems where accurately estimating the relationship between covariates and response variables is crucial, such as causal effect estimation. Existing methods for dealing with measurement error often rely on strong assumptions such as knowledge of the error distribution or its variance and availability of replicated measurements of the covariates. We propose a Bayesian Nonparametric Learning framework that is robust to mismeasured covariates, does not require the preceding assumptions, and can incorporate prior beliefs about the error distribution. This approach gives rise to a general framework that is suitable for both Classical and Berkson error models via the appropriate specification of the prior centering measure of a Dirichlet Process (DP). Moreover, it offers flexibility in the choice of loss function depending on the type of regression model. We provide bounds on the generalization error based on the Maximum Mean Discrepancy (MMD) loss which allows for generalization to non-Gaussian distributed errors and nonlinear covariate-response relationships. We showcase the effectiveness of the proposed framework versus prior art in real-world problems containing either Berkson or Classical measurement errors." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/04/30/RobustBayesianInferenceforBerksonandClassicalMeasurementErrorModels.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/04/30/RobustBayesianInferenceforBerksonandClassicalMeasurementErrorModels.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-04-30T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Robust Bayesian Inference for Berkson and Classical Measurement Error Models" />
<script type="application/ld+json">
{"description":"Measurement error occurs when a covariate influencing a response variable is corrupted by noise. This can lead to misleading inference outcomes, particularly in problems where accurately estimating the relationship between covariates and response variables is crucial, such as causal effect estimation. Existing methods for dealing with measurement error often rely on strong assumptions such as knowledge of the error distribution or its variance and availability of replicated measurements of the covariates. We propose a Bayesian Nonparametric Learning framework that is robust to mismeasured covariates, does not require the preceding assumptions, and can incorporate prior beliefs about the error distribution. This approach gives rise to a general framework that is suitable for both Classical and Berkson error models via the appropriate specification of the prior centering measure of a Dirichlet Process (DP). Moreover, it offers flexibility in the choice of loss function depending on the type of regression model. We provide bounds on the generalization error based on the Maximum Mean Discrepancy (MMD) loss which allows for generalization to non-Gaussian distributed errors and nonlinear covariate-response relationships. We showcase the effectiveness of the proposed framework versus prior art in real-world problems containing either Berkson or Classical measurement errors.","headline":"Robust Bayesian Inference for Berkson and Classical Measurement Error Models","dateModified":"2024-04-30T00:00:00+00:00","datePublished":"2024-04-30T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/04/30/RobustBayesianInferenceforBerksonandClassicalMeasurementErrorModels.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/04/30/RobustBayesianInferenceforBerksonandClassicalMeasurementErrorModels.html","author":{"@type":"Person","name":"Charita Dellaporta, Theodoros Damoulas"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-04-30 00:00:00 +0000">04-30</time>
  </p>
  
  <h1>Robust Bayesian Inference for Berkson and Classical Measurement Error Models</h1>
  <br>Charita Dellaporta, Theodoros Damoulas</h3>
  <br> [stat.ME,stat.ML]

  <p>Measurement error occurs when a covariate influencing a response variable is corrupted by noise. This can lead to misleading inference outcomes, particularly in problems where accurately estimating the relationship between covariates and response variables is crucial, such as causal effect estimation. Existing methods for dealing with measurement error often rely on strong assumptions such as knowledge of the error distribution or its variance and availability of replicated measurements of the covariates. We propose a Bayesian Nonparametric Learning framework that is robust to mismeasured covariates, does not require the preceding assumptions, and can incorporate prior beliefs about the error distribution. This approach gives rise to a general framework that is suitable for both Classical and Berkson error models via the appropriate specification of the prior centering measure of a Dirichlet Process (DP). Moreover, it offers flexibility in the choice of loss function depending on the type of regression model. We provide bounds on the generalization error based on the Maximum Mean Discrepancy (MMD) loss which allows for generalization to non-Gaussian distributed errors and nonlinear covariate-response relationships. We showcase the effectiveness of the proposed framework versus prior art in real-world problems containing either Berkson or Classical measurement errors.</p>

<p><a href="https://arxiv.org/abs/2306.01468">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>