<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>The ARR2 prior: flexible predictive prior definition for Bayesian auto-regressions</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="The ARR2 prior: flexible predictive prior definition for Bayesian auto-regressions" />
<meta name="author" content="David Kohns, Noa Kallionen, Yann McLatchie, Aki Vehtari" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We present the ARR2 prior, a joint prior over the auto-regressive components in Bayesian time-series models and their induced $R^2$. Compared to other priors designed for times-series models, the ARR2 prior allows for flexible and intuitive shrinkage. We derive the prior for pure auto-regressive models, and extend it to auto-regressive models with exogenous inputs, and state-space models. Through both simulations and real-world modelling exercises, we demonstrate the efficacy of the ARR2 prior in improving sparse and reliable inference, while showing greater inference quality and predictive performance than other shrinkage priors. An open-source implementation of the prior is provided." />
<meta property="og:description" content="We present the ARR2 prior, a joint prior over the auto-regressive components in Bayesian time-series models and their induced $R^2$. Compared to other priors designed for times-series models, the ARR2 prior allows for flexible and intuitive shrinkage. We derive the prior for pure auto-regressive models, and extend it to auto-regressive models with exogenous inputs, and state-space models. Through both simulations and real-world modelling exercises, we demonstrate the efficacy of the ARR2 prior in improving sparse and reliable inference, while showing greater inference quality and predictive performance than other shrinkage priors. An open-source implementation of the prior is provided." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/05/31/TheARR2priorflexiblepredictivepriordefinitionforBayesianautoregressions.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/05/31/TheARR2priorflexiblepredictivepriordefinitionforBayesianautoregressions.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-31T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The ARR2 prior: flexible predictive prior definition for Bayesian auto-regressions" />
<script type="application/ld+json">
{"description":"We present the ARR2 prior, a joint prior over the auto-regressive components in Bayesian time-series models and their induced $R^2$. Compared to other priors designed for times-series models, the ARR2 prior allows for flexible and intuitive shrinkage. We derive the prior for pure auto-regressive models, and extend it to auto-regressive models with exogenous inputs, and state-space models. Through both simulations and real-world modelling exercises, we demonstrate the efficacy of the ARR2 prior in improving sparse and reliable inference, while showing greater inference quality and predictive performance than other shrinkage priors. An open-source implementation of the prior is provided.","author":{"@type":"Person","name":"David Kohns, Noa Kallionen, Yann McLatchie, Aki Vehtari"},"datePublished":"2024-05-31T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/31/TheARR2priorflexiblepredictivepriordefinitionforBayesianautoregressions.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/31/TheARR2priorflexiblepredictivepriordefinitionforBayesianautoregressions.html","headline":"The ARR2 prior: flexible predictive prior definition for Bayesian auto-regressions","@type":"BlogPosting","dateModified":"2024-05-31T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-05-31 00:00:00 +0000">05-31</time>
  </p>
  
  <h1>The ARR2 prior: flexible predictive prior definition for Bayesian auto-regressions</h1>
  <br>David Kohns, Noa Kallionen, Yann McLatchie, Aki Vehtari</h3>
  <br> [stat.CO]

  <p>We present the ARR2 prior, a joint prior over the auto-regressive components in Bayesian time-series models and their induced $R^2$. Compared to other priors designed for times-series models, the ARR2 prior allows for flexible and intuitive shrinkage. We derive the prior for pure auto-regressive models, and extend it to auto-regressive models with exogenous inputs, and state-space models. Through both simulations and real-world modelling exercises, we demonstrate the efficacy of the ARR2 prior in improving sparse and reliable inference, while showing greater inference quality and predictive performance than other shrinkage priors. An open-source implementation of the prior is provided.</p>

<p><a href="https://arxiv.org/abs/2405.19920">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>