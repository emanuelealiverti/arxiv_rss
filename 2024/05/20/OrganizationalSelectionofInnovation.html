<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Organizational Selection of Innovation</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Organizational Selection of Innovation" />
<meta name="author" content="Lucas Böttcher, Ronald Klingebiel" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Budgetary constraints force organizations to pursue only a subset of possible innovation projects. Identifying which subset is most promising is an error-prone exercise, and involving multiple decision makers may be prudent. This raises the question of how to most effectively aggregate their collective nous. Our model of organizational portfolio selection provides some first answers. We show that portfolio performance can vary widely. Delegating evaluation makes sense when organizations employ the relevant experts and can assign projects to them. In most other settings, aggregating the impressions of multiple agents leads to better performance than delegation. In particular, letting agents rank projects often outperforms alternative aggregation rules – including averaging agents’ project scores as well as counting their approval votes – especially when organizations have tight budgets and can select only a few project alternatives out of many." />
<meta property="og:description" content="Budgetary constraints force organizations to pursue only a subset of possible innovation projects. Identifying which subset is most promising is an error-prone exercise, and involving multiple decision makers may be prudent. This raises the question of how to most effectively aggregate their collective nous. Our model of organizational portfolio selection provides some first answers. We show that portfolio performance can vary widely. Delegating evaluation makes sense when organizations employ the relevant experts and can assign projects to them. In most other settings, aggregating the impressions of multiple agents leads to better performance than delegation. In particular, letting agents rank projects often outperforms alternative aggregation rules – including averaging agents’ project scores as well as counting their approval votes – especially when organizations have tight budgets and can select only a few project alternatives out of many." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/05/20/OrganizationalSelectionofInnovation.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/05/20/OrganizationalSelectionofInnovation.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Organizational Selection of Innovation" />
<script type="application/ld+json">
{"description":"Budgetary constraints force organizations to pursue only a subset of possible innovation projects. Identifying which subset is most promising is an error-prone exercise, and involving multiple decision makers may be prudent. This raises the question of how to most effectively aggregate their collective nous. Our model of organizational portfolio selection provides some first answers. We show that portfolio performance can vary widely. Delegating evaluation makes sense when organizations employ the relevant experts and can assign projects to them. In most other settings, aggregating the impressions of multiple agents leads to better performance than delegation. In particular, letting agents rank projects often outperforms alternative aggregation rules – including averaging agents’ project scores as well as counting their approval votes – especially when organizations have tight budgets and can select only a few project alternatives out of many.","author":{"@type":"Person","name":"Lucas Böttcher, Ronald Klingebiel"},"datePublished":"2024-05-20T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/20/OrganizationalSelectionofInnovation.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/20/OrganizationalSelectionofInnovation.html","headline":"Organizational Selection of Innovation","@type":"BlogPosting","dateModified":"2024-05-20T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-05-20 00:00:00 +0000">05-20</time>
  </p>
  
  <h1>Organizational Selection of Innovation</h1>
  <br>Lucas Böttcher, Ronald Klingebiel</h3>
  <br> [stat.AP]

  <p>Budgetary constraints force organizations to pursue only a subset of possible innovation projects. Identifying which subset is most promising is an error-prone exercise, and involving multiple decision makers may be prudent. This raises the question of how to most effectively aggregate their collective nous. Our model of organizational portfolio selection provides some first answers. We show that portfolio performance can vary widely. Delegating evaluation makes sense when organizations employ the relevant experts and can assign projects to them. In most other settings, aggregating the impressions of multiple agents leads to better performance than delegation. In particular, letting agents rank projects often outperforms alternative aggregation rules – including averaging agents’ project scores as well as counting their approval votes – especially when organizations have tight budgets and can select only a few project alternatives out of many.</p>

<p><a href="https://arxiv.org/abs/2405.09843">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>