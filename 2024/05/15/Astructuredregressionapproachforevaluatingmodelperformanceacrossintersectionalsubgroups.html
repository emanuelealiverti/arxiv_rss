<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>A structured regression approach for evaluating model performance across intersectional subgroups</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="A structured regression approach for evaluating model performance across intersectional subgroups" />
<meta name="author" content="Christine Herlihy, Kimberly Truong, Alexandra Chouldechova, Miroslav Dudik" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Disaggregated evaluation is a central task in AI fairness assessment, where the goal is to measure an AI system’s performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are included in analysis. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectional groups. We evaluate our approach on two publicly available datasets, and several variants of semi-synthetic data. The results show that our method is considerably more accurate than the standard approach, especially for small subgroups, and demonstrate how goodness-of-fit testing helps identify the key factors that drive differences in performance." />
<meta property="og:description" content="Disaggregated evaluation is a central task in AI fairness assessment, where the goal is to measure an AI system’s performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are included in analysis. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectional groups. We evaluate our approach on two publicly available datasets, and several variants of semi-synthetic data. The results show that our method is considerably more accurate than the standard approach, especially for small subgroups, and demonstrate how goodness-of-fit testing helps identify the key factors that drive differences in performance." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/05/15/Astructuredregressionapproachforevaluatingmodelperformanceacrossintersectionalsubgroups.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/05/15/Astructuredregressionapproachforevaluatingmodelperformanceacrossintersectionalsubgroups.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-15T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A structured regression approach for evaluating model performance across intersectional subgroups" />
<script type="application/ld+json">
{"description":"Disaggregated evaluation is a central task in AI fairness assessment, where the goal is to measure an AI system’s performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are included in analysis. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectional groups. We evaluate our approach on two publicly available datasets, and several variants of semi-synthetic data. The results show that our method is considerably more accurate than the standard approach, especially for small subgroups, and demonstrate how goodness-of-fit testing helps identify the key factors that drive differences in performance.","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/15/Astructuredregressionapproachforevaluatingmodelperformanceacrossintersectionalsubgroups.html"},"headline":"A structured regression approach for evaluating model performance across intersectional subgroups","dateModified":"2024-05-15T00:00:00+00:00","datePublished":"2024-05-15T00:00:00+00:00","url":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/15/Astructuredregressionapproachforevaluatingmodelperformanceacrossintersectionalsubgroups.html","author":{"@type":"Person","name":"Christine Herlihy, Kimberly Truong, Alexandra Chouldechova, Miroslav Dudik"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-05-15 00:00:00 +0000">05-15</time>
  </p>
  
  <h1>A structured regression approach for evaluating model performance across intersectional subgroups</h1>
  <br>Christine Herlihy, Kimberly Truong, Alexandra Chouldechova, Miroslav Dudik</h3>
  <br> [stat.AP,stat.ML]

  <p>Disaggregated evaluation is a central task in AI fairness assessment, where the goal is to measure an AI system’s performance across different subgroups defined by combinations of demographic or other sensitive attributes. The standard approach is to stratify the evaluation data across subgroups and compute performance metrics separately for each group. However, even for moderately-sized evaluation datasets, sample sizes quickly get small once considering intersectional subgroups, which greatly limits the extent to which intersectional groups are included in analysis. In this work, we introduce a structured regression approach to disaggregated evaluation that we demonstrate can yield reliable system performance estimates even for very small subgroups. We provide corresponding inference strategies for constructing confidence intervals and explore how goodness-of-fit testing can yield insight into the structure of fairness-related harms experienced by intersectional groups. We evaluate our approach on two publicly available datasets, and several variants of semi-synthetic data. The results show that our method is considerably more accurate than the standard approach, especially for small subgroups, and demonstrate how goodness-of-fit testing helps identify the key factors that drive differences in performance.</p>

<p><a href="https://arxiv.org/abs/2401.14893">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>