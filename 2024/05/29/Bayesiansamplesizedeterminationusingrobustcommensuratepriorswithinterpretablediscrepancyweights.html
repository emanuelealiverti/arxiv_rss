<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Bayesian sample size determination using robust commensurate priors with interpretable discrepancy weights</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Bayesian sample size determination using robust commensurate priors with interpretable discrepancy weights" />
<meta name="author" content="Lou E. Whitehead, James M. S. Wason, Oliver Sailer, Haiyan Zheng" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Randomized controlled clinical trials provide the gold standard for evidence generation in relation to the efficacy of a new treatment in medical research. Relevant information from previous studies may be desirable to incorporate in the design and analysis of a new trial, with the Bayesian paradigm providing a coherent framework to formally incorporate prior knowledge. Many established methods involve the use of a discounting factor, sometimes related to a measure of similarity&#39; between historical and the new trials. However, it is often the case that the sample size is highly nonlinear in those discounting factors. This hinders communication with subject-matter experts to elicit sensible values for borrowing strength at the trial design stage. Focusing on a commensurate predictive prior method that can incorporate historical data from multiple sources, we highlight a particular issue of nonmonotonicity and explain why this causes issues with interpretability of the discounting factors (hereafter referred to as weights’). We propose a solution for this, from which an analytical sample size formula is derived. We then propose a linearization technique such that the sample size changes uniformly over the weights. Our approach leads to interpretable weights that represent the probability that historical data are (ir)relevant to the new trial, and could therefore facilitate easier elicitation of expert opinion on their values. Keywords: Bayesian sample size determination; Commensurate priors; Historical borrowing; Prior aggregation; Uniform shrinkage." />
<meta property="og:description" content="Randomized controlled clinical trials provide the gold standard for evidence generation in relation to the efficacy of a new treatment in medical research. Relevant information from previous studies may be desirable to incorporate in the design and analysis of a new trial, with the Bayesian paradigm providing a coherent framework to formally incorporate prior knowledge. Many established methods involve the use of a discounting factor, sometimes related to a measure of similarity&#39; between historical and the new trials. However, it is often the case that the sample size is highly nonlinear in those discounting factors. This hinders communication with subject-matter experts to elicit sensible values for borrowing strength at the trial design stage. Focusing on a commensurate predictive prior method that can incorporate historical data from multiple sources, we highlight a particular issue of nonmonotonicity and explain why this causes issues with interpretability of the discounting factors (hereafter referred to as weights’). We propose a solution for this, from which an analytical sample size formula is derived. We then propose a linearization technique such that the sample size changes uniformly over the weights. Our approach leads to interpretable weights that represent the probability that historical data are (ir)relevant to the new trial, and could therefore facilitate easier elicitation of expert opinion on their values. Keywords: Bayesian sample size determination; Commensurate priors; Historical borrowing; Prior aggregation; Uniform shrinkage." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/05/29/Bayesiansamplesizedeterminationusingrobustcommensuratepriorswithinterpretablediscrepancyweights.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/05/29/Bayesiansamplesizedeterminationusingrobustcommensuratepriorswithinterpretablediscrepancyweights.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-29T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Bayesian sample size determination using robust commensurate priors with interpretable discrepancy weights" />
<script type="application/ld+json">
{"description":"Randomized controlled clinical trials provide the gold standard for evidence generation in relation to the efficacy of a new treatment in medical research. Relevant information from previous studies may be desirable to incorporate in the design and analysis of a new trial, with the Bayesian paradigm providing a coherent framework to formally incorporate prior knowledge. Many established methods involve the use of a discounting factor, sometimes related to a measure of similarity&#39; between historical and the new trials. However, it is often the case that the sample size is highly nonlinear in those discounting factors. This hinders communication with subject-matter experts to elicit sensible values for borrowing strength at the trial design stage. Focusing on a commensurate predictive prior method that can incorporate historical data from multiple sources, we highlight a particular issue of nonmonotonicity and explain why this causes issues with interpretability of the discounting factors (hereafter referred to as weights’). We propose a solution for this, from which an analytical sample size formula is derived. We then propose a linearization technique such that the sample size changes uniformly over the weights. Our approach leads to interpretable weights that represent the probability that historical data are (ir)relevant to the new trial, and could therefore facilitate easier elicitation of expert opinion on their values. Keywords: Bayesian sample size determination; Commensurate priors; Historical borrowing; Prior aggregation; Uniform shrinkage.","author":{"@type":"Person","name":"Lou E. Whitehead, James M. S. Wason, Oliver Sailer, Haiyan Zheng"},"datePublished":"2024-05-29T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/29/Bayesiansamplesizedeterminationusingrobustcommensuratepriorswithinterpretablediscrepancyweights.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/29/Bayesiansamplesizedeterminationusingrobustcommensuratepriorswithinterpretablediscrepancyweights.html","headline":"Bayesian sample size determination using robust commensurate priors with interpretable discrepancy weights","@type":"BlogPosting","dateModified":"2024-05-29T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-05-29 00:00:00 +0000">05-29</time>
  </p>
  
  <h1>Bayesian sample size determination using robust commensurate priors with interpretable discrepancy weights</h1>
  <br>Lou E. Whitehead, James M. S. Wason, Oliver Sailer, Haiyan Zheng</h3>
  <br> [stat.ME,stat.AP]

  <p>Randomized controlled clinical trials provide the gold standard for evidence generation in relation to the efficacy of a new treatment in medical research. Relevant information from previous studies may be desirable to incorporate in the design and analysis of a new trial, with the Bayesian paradigm providing a coherent framework to formally incorporate prior knowledge. Many established methods involve the use of a discounting factor, sometimes related to a measure of <code class="language-plaintext highlighter-rouge">similarity' between historical and the new trials. However, it is often the case that the sample size is highly nonlinear in those discounting factors. This hinders communication with subject-matter experts to elicit sensible values for borrowing strength at the trial design stage. Focusing on a commensurate predictive prior method that can incorporate historical data from multiple sources, we highlight a particular issue of nonmonotonicity and explain why this causes issues with interpretability of the discounting factors (hereafter referred to as </code>weights’). We propose a solution for this, from which an analytical sample size formula is derived. We then propose a linearization technique such that the sample size changes uniformly over the weights. Our approach leads to interpretable weights that represent the probability that historical data are (ir)relevant to the new trial, and could therefore facilitate easier elicitation of expert opinion on their values.
  Keywords: Bayesian sample size determination; Commensurate priors; Historical borrowing; Prior aggregation; Uniform shrinkage.</p>

<p><a href="https://arxiv.org/abs/2401.10592">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>