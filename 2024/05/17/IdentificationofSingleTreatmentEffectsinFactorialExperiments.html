<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Identification of Single-Treatment Effects in Factorial Experiments</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Identification of Single-Treatment Effects in Factorial Experiments" />
<meta name="author" content="Guilherme Duarte" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Despite their cost, randomized controlled trials (RCTs) are widely regarded as gold-standard evidence in disciplines ranging from social science to medicine. In recent decades, researchers have increasingly sought to reduce the resource burden of repeated RCTs with factorial designs that simultaneously test multiple hypotheses, e.g. experiments that evaluate the effects of many medications or products simultaneously. Here I show that when multiple interventions are randomized in experiments, the effect any single intervention would have outside the experimental setting is not identified absent heroic assumptions, even if otherwise perfectly realistic conditions are achieved. This happens because single-treatment effects involve a counterfactual world with a single focal intervention, allowing other variables to take their natural values (which may be confounded or modified by the focal intervention). In contrast, observational studies and factorial experiments provide information about potential-outcome distributions with zero and multiple interventions, respectively. In this paper, I formalize sufficient conditions for the identifiability of those isolated quantities. I show that researchers who rely on this type of design have to justify either linearity of functional forms or – in the nonparametric case – specify with Directed Acyclic Graphs how variables are related in the real world. Finally, I develop nonparametric sharp bounds – i.e., maximally informative best-/worst-case estimates consistent with limited RCT data – that show when extrapolations about effect signs are empirically justified. These new results are illustrated with simulated data." />
<meta property="og:description" content="Despite their cost, randomized controlled trials (RCTs) are widely regarded as gold-standard evidence in disciplines ranging from social science to medicine. In recent decades, researchers have increasingly sought to reduce the resource burden of repeated RCTs with factorial designs that simultaneously test multiple hypotheses, e.g. experiments that evaluate the effects of many medications or products simultaneously. Here I show that when multiple interventions are randomized in experiments, the effect any single intervention would have outside the experimental setting is not identified absent heroic assumptions, even if otherwise perfectly realistic conditions are achieved. This happens because single-treatment effects involve a counterfactual world with a single focal intervention, allowing other variables to take their natural values (which may be confounded or modified by the focal intervention). In contrast, observational studies and factorial experiments provide information about potential-outcome distributions with zero and multiple interventions, respectively. In this paper, I formalize sufficient conditions for the identifiability of those isolated quantities. I show that researchers who rely on this type of design have to justify either linearity of functional forms or – in the nonparametric case – specify with Directed Acyclic Graphs how variables are related in the real world. Finally, I develop nonparametric sharp bounds – i.e., maximally informative best-/worst-case estimates consistent with limited RCT data – that show when extrapolations about effect signs are empirically justified. These new results are illustrated with simulated data." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/05/17/IdentificationofSingleTreatmentEffectsinFactorialExperiments.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/05/17/IdentificationofSingleTreatmentEffectsinFactorialExperiments.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-17T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Identification of Single-Treatment Effects in Factorial Experiments" />
<script type="application/ld+json">
{"description":"Despite their cost, randomized controlled trials (RCTs) are widely regarded as gold-standard evidence in disciplines ranging from social science to medicine. In recent decades, researchers have increasingly sought to reduce the resource burden of repeated RCTs with factorial designs that simultaneously test multiple hypotheses, e.g. experiments that evaluate the effects of many medications or products simultaneously. Here I show that when multiple interventions are randomized in experiments, the effect any single intervention would have outside the experimental setting is not identified absent heroic assumptions, even if otherwise perfectly realistic conditions are achieved. This happens because single-treatment effects involve a counterfactual world with a single focal intervention, allowing other variables to take their natural values (which may be confounded or modified by the focal intervention). In contrast, observational studies and factorial experiments provide information about potential-outcome distributions with zero and multiple interventions, respectively. In this paper, I formalize sufficient conditions for the identifiability of those isolated quantities. I show that researchers who rely on this type of design have to justify either linearity of functional forms or – in the nonparametric case – specify with Directed Acyclic Graphs how variables are related in the real world. Finally, I develop nonparametric sharp bounds – i.e., maximally informative best-/worst-case estimates consistent with limited RCT data – that show when extrapolations about effect signs are empirically justified. These new results are illustrated with simulated data.","author":{"@type":"Person","name":"Guilherme Duarte"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/17/IdentificationofSingleTreatmentEffectsinFactorialExperiments.html"},"dateModified":"2024-05-17T00:00:00+00:00","url":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/17/IdentificationofSingleTreatmentEffectsinFactorialExperiments.html","headline":"Identification of Single-Treatment Effects in Factorial Experiments","@type":"BlogPosting","datePublished":"2024-05-17T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-05-17 00:00:00 +0000">05-17</time>
  </p>
  
  <h1>Identification of Single-Treatment Effects in Factorial Experiments</h1>
  <br>Guilherme Duarte</h3>
  <br> [stat.ME,stat.ML,stat.OT]

  <p>Despite their cost, randomized controlled trials (RCTs) are widely regarded as gold-standard evidence in disciplines ranging from social science to medicine. In recent decades, researchers have increasingly sought to reduce the resource burden of repeated RCTs with factorial designs that simultaneously test multiple hypotheses, e.g. experiments that evaluate the effects of many medications or products simultaneously. Here I show that when multiple interventions are randomized in experiments, the effect any single intervention would have outside the experimental setting is not identified absent heroic assumptions, even if otherwise perfectly realistic conditions are achieved. This happens because single-treatment effects involve a counterfactual world with a single focal intervention, allowing other variables to take their natural values (which may be confounded or modified by the focal intervention). In contrast, observational studies and factorial experiments provide information about potential-outcome distributions with zero and multiple interventions, respectively. In this paper, I formalize sufficient conditions for the identifiability of those isolated quantities. I show that researchers who rely on this type of design have to justify either linearity of functional forms or – in the nonparametric case – specify with Directed Acyclic Graphs how variables are related in the real world. Finally, I develop nonparametric sharp bounds – i.e., maximally informative best-/worst-case estimates consistent with limited RCT data – that show when extrapolations about effect signs are empirically justified. These new results are illustrated with simulated data.</p>

<p><a href="https://arxiv.org/abs/2405.09797">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>