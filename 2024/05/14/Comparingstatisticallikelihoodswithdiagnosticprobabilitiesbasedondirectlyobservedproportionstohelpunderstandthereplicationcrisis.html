<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Comparing statistical likelihoods with diagnostic probabilities based on directly observed proportions to help understand the replication crisis</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Comparing statistical likelihoods with diagnostic probabilities based on directly observed proportions to help understand the replication crisis" />
<meta name="author" content="Huw Llewelyn" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Diagnosticians use an observed proportion as a direct estimate of the posterior probability of a diagnosis. Therefore, a diagnostician might regard a continuous Gaussian probability distribution of possible numerical outcomes conditional on the information in the study methods and data as posterior probabilities. Similarly, they might regard the distribution of possible means based on a SEM as a posterior probability distribution too. If the converse likelihood distribution of the observed mean conditional on any hypothetical mean (e.g. the null hypothesis) is assumed to be the same as the above posterior distribution (as is customary) then by Bayes rule, the prior distribution of all possible hypothetical means is uniform. It follows that the probability Q of any theoretically true mean falling into a tail beyond a null hypothesis would be equal to that tails area as a proportion of the whole. It also follows that the P value (the probability of the observed mean or something more extreme conditional on the null hypothesis) is equal to Q. Replication involves doing two independent studies, thus doubling the variance for the combined posterior probability distribution. So, if the original effect size was 1.96, the number of observations was 100, the SEM was 1 and the original P value was 0.025, the theoretical probability of a replicating study getting a P value of up to 0.025 again is only 0.283. By applying this double variance to achieve a power of 80%, the required number of observations is doubled compared to conventional approaches. If some replicating study is to achieve a P value of up to 0.025 yet again with a probability of 0.8, then this requires 3 times as many observations in the power calculation. This might explain the replication crisis." />
<meta property="og:description" content="Diagnosticians use an observed proportion as a direct estimate of the posterior probability of a diagnosis. Therefore, a diagnostician might regard a continuous Gaussian probability distribution of possible numerical outcomes conditional on the information in the study methods and data as posterior probabilities. Similarly, they might regard the distribution of possible means based on a SEM as a posterior probability distribution too. If the converse likelihood distribution of the observed mean conditional on any hypothetical mean (e.g. the null hypothesis) is assumed to be the same as the above posterior distribution (as is customary) then by Bayes rule, the prior distribution of all possible hypothetical means is uniform. It follows that the probability Q of any theoretically true mean falling into a tail beyond a null hypothesis would be equal to that tails area as a proportion of the whole. It also follows that the P value (the probability of the observed mean or something more extreme conditional on the null hypothesis) is equal to Q. Replication involves doing two independent studies, thus doubling the variance for the combined posterior probability distribution. So, if the original effect size was 1.96, the number of observations was 100, the SEM was 1 and the original P value was 0.025, the theoretical probability of a replicating study getting a P value of up to 0.025 again is only 0.283. By applying this double variance to achieve a power of 80%, the required number of observations is doubled compared to conventional approaches. If some replicating study is to achieve a P value of up to 0.025 yet again with a probability of 0.8, then this requires 3 times as many observations in the power calculation. This might explain the replication crisis." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/05/14/Comparingstatisticallikelihoodswithdiagnosticprobabilitiesbasedondirectlyobservedproportionstohelpunderstandthereplicationcrisis.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/05/14/Comparingstatisticallikelihoodswithdiagnosticprobabilitiesbasedondirectlyobservedproportionstohelpunderstandthereplicationcrisis.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-05-14T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Comparing statistical likelihoods with diagnostic probabilities based on directly observed proportions to help understand the replication crisis" />
<script type="application/ld+json">
{"description":"Diagnosticians use an observed proportion as a direct estimate of the posterior probability of a diagnosis. Therefore, a diagnostician might regard a continuous Gaussian probability distribution of possible numerical outcomes conditional on the information in the study methods and data as posterior probabilities. Similarly, they might regard the distribution of possible means based on a SEM as a posterior probability distribution too. If the converse likelihood distribution of the observed mean conditional on any hypothetical mean (e.g. the null hypothesis) is assumed to be the same as the above posterior distribution (as is customary) then by Bayes rule, the prior distribution of all possible hypothetical means is uniform. It follows that the probability Q of any theoretically true mean falling into a tail beyond a null hypothesis would be equal to that tails area as a proportion of the whole. It also follows that the P value (the probability of the observed mean or something more extreme conditional on the null hypothesis) is equal to Q. Replication involves doing two independent studies, thus doubling the variance for the combined posterior probability distribution. So, if the original effect size was 1.96, the number of observations was 100, the SEM was 1 and the original P value was 0.025, the theoretical probability of a replicating study getting a P value of up to 0.025 again is only 0.283. By applying this double variance to achieve a power of 80%, the required number of observations is doubled compared to conventional approaches. If some replicating study is to achieve a P value of up to 0.025 yet again with a probability of 0.8, then this requires 3 times as many observations in the power calculation. This might explain the replication crisis.","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/14/Comparingstatisticallikelihoodswithdiagnosticprobabilitiesbasedondirectlyobservedproportionstohelpunderstandthereplicationcrisis.html"},"headline":"Comparing statistical likelihoods with diagnostic probabilities based on directly observed proportions to help understand the replication crisis","dateModified":"2024-05-14T00:00:00+00:00","datePublished":"2024-05-14T00:00:00+00:00","url":"https://emanuelealiverti.github.io/arxiv_rss/2024/05/14/Comparingstatisticallikelihoodswithdiagnosticprobabilitiesbasedondirectlyobservedproportionstohelpunderstandthereplicationcrisis.html","author":{"@type":"Person","name":"Huw Llewelyn"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-05-14 00:00:00 +0000">05-14</time>
  </p>
  
  <h1>Comparing statistical likelihoods with diagnostic probabilities based on directly observed proportions to help understand the replication crisis</h1>
  <br>Huw Llewelyn</h3>
  <br> [stat.ME]

  <p>Diagnosticians use an observed proportion as a direct estimate of the posterior probability of a diagnosis. Therefore, a diagnostician might regard a continuous Gaussian probability distribution of possible numerical outcomes conditional on the information in the study methods and data as posterior probabilities. Similarly, they might regard the distribution of possible means based on a SEM as a posterior probability distribution too. If the converse likelihood distribution of the observed mean conditional on any hypothetical mean (e.g. the null hypothesis) is assumed to be the same as the above posterior distribution (as is customary) then by Bayes rule, the prior distribution of all possible hypothetical means is uniform. It follows that the probability Q of any theoretically true mean falling into a tail beyond a null hypothesis would be equal to that tails area as a proportion of the whole. It also follows that the P value (the probability of the observed mean or something more extreme conditional on the null hypothesis) is equal to Q. Replication involves doing two independent studies, thus doubling the variance for the combined posterior probability distribution. So, if the original effect size was 1.96, the number of observations was 100, the SEM was 1 and the original P value was 0.025, the theoretical probability of a replicating study getting a P value of up to 0.025 again is only 0.283. By applying this double variance to achieve a power of 80%, the required number of observations is doubled compared to conventional approaches. If some replicating study is to achieve a P value of up to 0.025 yet again with a probability of 0.8, then this requires 3 times as many observations in the power calculation. This might explain the replication crisis.</p>

<p><a href="https://arxiv.org/abs/2403.16906">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>